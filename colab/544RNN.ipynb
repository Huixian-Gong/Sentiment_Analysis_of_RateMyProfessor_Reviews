{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fvClTLECx5cc",
    "outputId": "60bae289-f8ee-4eb3-f23a-ff7e2f134ea8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "  Using cached nltk-3.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting click (from nltk)\n",
      "  Using cached click-8.1.7-py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: joblib in /Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages (from nltk) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages (from nltk) (2024.11.6)\n",
      "Requirement already satisfied: tqdm in /Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages (from nltk) (4.67.0)\n",
      "Using cached nltk-3.9.1-py3-none-any.whl (1.5 MB)\n",
      "Using cached click-8.1.7-py3-none-any.whl (97 kB)\n",
      "Installing collected packages: click, nltk\n",
      "Successfully installed click-8.1.7 nltk-3.9.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install contractions\n",
    "# !pip install tensorflow\n",
    "# !pip install transformers\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "a_oZbd9hxSMw"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import accuracy_score, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "8sC__B3FxtOA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tqdm\n",
    "import transformers\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "import contractions\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Cor_HHenxgJ2",
    "outputId": "c28f659f-6765-46ef-a4e3-9ea2606b7181"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 comment  star_rating  \\\n",
      "0      our final exam in dr farber art 102 class cons...          1.0   \n",
      "1      my last review wa taken down for unknown reaso...          1.0   \n",
      "2      i have written a review of thi professor befor...          1.0   \n",
      "3      i went into thi class super excit to analyz so...          1.0   \n",
      "4      thi class involv a lot of memor and will take ...          3.0   \n",
      "...                                                  ...          ...   \n",
      "35042  she is a veri attent and effect teacher in my ...          5.0   \n",
      "35043  it the most interest class i have ever taken i...          5.0   \n",
      "35044  all you will need is elizabeth note amaz struc...          3.5   \n",
      "35045  waaaaay better than britten take hi cours he g...          4.5   \n",
      "35046  he is veri smartwitti understand and help alwa...          3.5   \n",
      "\n",
      "       course_difficulty  gives_good_feedback  caring  respected  \\\n",
      "0                    5.0                    0       0          0   \n",
      "1                    5.0                    0       0          0   \n",
      "2                    5.0                    0       0          0   \n",
      "3                    3.0                    0       0          0   \n",
      "4                    4.0                    0       0          0   \n",
      "...                  ...                  ...     ...        ...   \n",
      "35042                2.0                    0       0          0   \n",
      "35043                4.0                    0       0          0   \n",
      "35044                2.0                    0       0          0   \n",
      "35045                2.0                    0       0          0   \n",
      "35046                3.0                    0       0          0   \n",
      "\n",
      "       participation_matters  clear_grading_criteria  amazing_lectures  \\\n",
      "0                          0                       0                 0   \n",
      "1                          0                       0                 0   \n",
      "2                          1                       0                 0   \n",
      "3                          0                       0                 0   \n",
      "4                          0                       0                 0   \n",
      "...                      ...                     ...               ...   \n",
      "35042                      0                       0                 0   \n",
      "35043                      0                       0                 0   \n",
      "35044                      0                       0                 0   \n",
      "35045                      0                       0                 0   \n",
      "35046                      0                       0                 0   \n",
      "\n",
      "       inspirational  ...  lecture_heavy  extra_credit  graded_by_few_things  \\\n",
      "0                  0  ...              1             0                     1   \n",
      "1                  0  ...              1             0                     1   \n",
      "2                  0  ...              0             0                     0   \n",
      "3                  0  ...              1             0                     0   \n",
      "4                  0  ...              1             0                     1   \n",
      "...              ...  ...            ...           ...                   ...   \n",
      "35042              0  ...              0             0                     0   \n",
      "35043              0  ...              0             0                     0   \n",
      "35044              0  ...              0             0                     0   \n",
      "35045              0  ...              0             0                     0   \n",
      "35046              0  ...              0             0                     0   \n",
      "\n",
      "       group_projects  would_take_again  skip_class_you_wont_pass  test_heavy  \\\n",
      "0                   0                 0                         0           0   \n",
      "1                   0                 0                         0           0   \n",
      "2                   0                 0                         0           0   \n",
      "3                   0                 0                         0           0   \n",
      "4                   0                 0                         0           0   \n",
      "...               ...               ...                       ...         ...   \n",
      "35042               0                 0                         0           0   \n",
      "35043               0                 0                         0           0   \n",
      "35044               0                 0                         0           0   \n",
      "35045               0                 0                         0           0   \n",
      "35046               0                 0                         0           0   \n",
      "\n",
      "       so_many_papers  beware_of_pop_quizzes  tests_are_tough  \n",
      "0                   0                      0                0  \n",
      "1                   0                      0                0  \n",
      "2                   0                      0                0  \n",
      "3                   0                      0                0  \n",
      "4                   0                      0                0  \n",
      "...               ...                    ...              ...  \n",
      "35042               0                      0                0  \n",
      "35043               0                      0                0  \n",
      "35044               0                      0                0  \n",
      "35045               0                      0                0  \n",
      "35046               0                      0                0  \n",
      "\n",
      "[35047 rows x 25 columns]\n"
     ]
    }
   ],
   "source": [
    "raw_data = pd.read_csv('/Users/yuanshenwang/Desktop/Sentiment_Analysis_of_RateMyProfessor_Reviews/data/new_data/complete_set.csv')\n",
    "print(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "id": "WJUeiA53zVUP"
   },
   "outputs": [],
   "source": [
    "X = raw_data['comment']\n",
    "y = raw_data.drop('comment', axis=1)\n",
    "# y = raw_data[['star_rating','course_difficulty']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WzJwwwj4zm4N",
    "outputId": "1a4747d6-d0d6-48b2-bff9-ab0e2b8c3d75"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of input data (X):\n",
      "Comment 1: our final exam in dr farber art 102 class consist of memor everi singl detail of a 70 page studi gui...\n",
      "Comment 2: my last review wa taken down for unknown reason nevertheless i had dr faber and i have to agre with ...\n",
      "Comment 3: i have written a review of thi professor befor but for some reason it wa never post odd consid it wa...\n",
      "Comment 4: i went into thi class super excit to analyz some renaiss art and discuss theme of enlighten and so o...\n",
      "Comment 5: thi class involv a lot of memor and will take up a lot of time onc final and midterm start class is ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Sample of input data (X):\")\n",
    "for i in range(5):  # Print first 5 comments\n",
    "    print(f\"Comment {i+1}: {X[i][:100]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "6u-B6jnHzscv"
   },
   "outputs": [],
   "source": [
    "X = raw_data['comment']\n",
    "# y = raw_data[['Star_Rating', 'Course_Difficulty']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "R7DMhCYVzvJz"
   },
   "outputs": [],
   "source": [
    "max_words = 10000\n",
    "max_len = 142 # max comment length\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X)\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "X_pad = pad_sequences(X_seq, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "U6gsX36LzybQ"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ix8LPuhSz25G",
    "outputId": "8f097d6a-3e22-44aa-bfc5-78aed22ca240"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['star_rating', 'course_difficulty', 'gives_good_feedback', 'caring', 'respected', 'participation_matters', 'clear_grading_criteria', 'amazing_lectures', 'inspirational', 'tough_grader', 'hilarious', 'get_ready_to_read', 'lots_of_homework', 'accessible_outside_class', 'lecture_heavy', 'extra_credit', 'graded_by_few_things', 'group_projects', 'would_take_again', 'skip_class_you_wont_pass', 'test_heavy', 'so_many_papers', 'beware_of_pop_quizzes', 'tests_are_tough']\n"
     ]
    }
   ],
   "source": [
    "target_columns = y.columns.tolist()\n",
    "print(target_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "WZ54bgB7z-84"
   },
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "embedding_dim = max_len\n",
    "\n",
    "input_layer = Input(shape=(max_len,))\n",
    "embedding_layer = Embedding(vocab_size, embedding_dim)(input_layer)\n",
    "lstm_layer1 = LSTM(64, return_sequences=True)(embedding_layer)\n",
    "lstm_layer2 = LSTM(32)(lstm_layer1)\n",
    "dense_layer = Dense(64, activation='relu')(lstm_layer2)\n",
    "dropout_layer = Dropout(0.5)(dense_layer)\n",
    "\n",
    "outputs = []\n",
    "for column in target_columns:\n",
    "    if y[column].dtype == 'float64':\n",
    "        # For continuous variables (like 'student_star' and 'student_difficult')\n",
    "        outputs.append(Dense(1, name=column)(dropout_layer))\n",
    "    else:\n",
    "        # For binary variables (assuming 0 or 1)\n",
    "        outputs.append(Dense(1, activation='sigmoid', name=column)(dropout_layer))\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.layers import Input, Embedding, LSTM, Dense, Dropout\n",
    "# from keras.models import Model\n",
    "\n",
    "# embedding_dim = max_len\n",
    "\n",
    "# input_layer = Input(shape=(max_len,))\n",
    "# embedding_layer = Embedding(vocab_size, embedding_dim)(input_layer)\n",
    "# lstm_layer1 = LSTM(64, return_sequences=True)(embedding_layer)\n",
    "# lstm_layer2 = LSTM(32)(lstm_layer1)\n",
    "# dense_layer = Dense(64, activation='relu')(lstm_layer2)\n",
    "# dropout_layer = Dropout(0.5)(dense_layer)\n",
    "\n",
    "# outputs = []\n",
    "# for column in target_columns:\n",
    "#     if y[column].dtype == 'float64':\n",
    "#         # Continuous variables\n",
    "#         outputs.append(Dense(1, name=column)(dropout_layer))\n",
    "#     else:\n",
    "#         # Binary variables\n",
    "#         outputs.append(Dense(1, activation='sigmoid', name=column)(dropout_layer))\n",
    "\n",
    "# model = Model(inputs=input_layer, outputs=outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "id": "oPFk-cGr0CAN"
   },
   "outputs": [],
   "source": [
    "losses = ['mse' if y[col].dtype == 'float64' else 'BinaryFocalCrossentropy' for col in target_columns]\n",
    "metrics = []\n",
    "\n",
    "for col in target_columns:\n",
    "    if y[col].dtype == 'float64':\n",
    "        metrics.append(tf.keras.metrics.MeanAbsoluteError(name=f'{col}_mae'))\n",
    "    else:\n",
    "        metrics.append(tf.keras.metrics.Recall(name=f'{col}_recall'))\n",
    "\n",
    "# Compile the model with the updated losses and metrics\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss=losses,\n",
    "    loss_weights=[1.0] * len(target_columns),\n",
    "    metrics=metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 512
    },
    "id": "VDOU6piG0Ec2",
    "outputId": "65fdb26f-bbd0-4d71-917a-8b6561a667a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_4\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_4\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">142</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">142</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">142</span>)  │  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,806,062</span> │ input_layer_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]… │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">142</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">52,992</span> │ embedding_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │ lstm_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │ lstm_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ star_rating (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ course_difficulty   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gives_good_feedback │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ caring (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ respected (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ participation_matt… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ clear_grading_crit… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ amazing_lectures    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ inspirational       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tough_grader        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hilarious (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_ready_to_read   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lots_of_homework    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ accessible_outside… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lecture_heavy       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ extra_credit        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ graded_by_few_thin… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ group_projects      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ would_take_again    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ skip_class_you_won… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ test_heavy (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ so_many_papers      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ beware_of_pop_quiz… │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tests_are_tough     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_4       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m142\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ embedding_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m142\u001b[0m, \u001b[38;5;34m142\u001b[0m)  │  \u001b[38;5;34m2,806,062\u001b[0m │ input_layer_4[\u001b[38;5;34m0\u001b[0m]… │\n",
       "│ (\u001b[38;5;33mEmbedding\u001b[0m)         │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_8 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m142\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │     \u001b[38;5;34m52,992\u001b[0m │ embedding_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lstm_9 (\u001b[38;5;33mLSTM\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │     \u001b[38;5;34m12,416\u001b[0m │ lstm_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m2,112\u001b[0m │ lstm_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m0\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ star_rating (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ course_difficulty   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ gives_good_feedback │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ caring (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ respected (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ participation_matt… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ clear_grading_crit… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ amazing_lectures    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ inspirational       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tough_grader        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ hilarious (\u001b[38;5;33mDense\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ get_ready_to_read   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lots_of_homework    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ accessible_outside… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lecture_heavy       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ extra_credit        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ graded_by_few_thin… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ group_projects      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ would_take_again    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ skip_class_you_won… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ test_heavy (\u001b[38;5;33mDense\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ so_many_papers      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ beware_of_pop_quiz… │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ tests_are_tough     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "│ (\u001b[38;5;33mDense\u001b[0m)             │                   │            │                   │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,875,142</span> (10.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,875,142\u001b[0m (10.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,875,142</span> (10.97 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,875,142\u001b[0m (10.97 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "L_POB8_N0Wjs",
    "outputId": "c6b06bbc-2154-4bae-fefa-a4560fb9f7df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m701/701\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 153ms/step - accessible_outside_class_accessible_outside_class_recall: 0.0000e+00 - accessible_outside_class_loss: 0.1027 - amazing_lectures_amazing_lectures_recall: 0.0706 - amazing_lectures_loss: 0.0920 - beware_of_pop_quizzes_beware_of_pop_quizzes_recall: 0.0000e+00 - beware_of_pop_quizzes_loss: 0.0470 - caring_caring_recall: 0.0693 - caring_loss: 0.1022 - clear_grading_criteria_clear_grading_criteria_recall: 0.0000e+00 - clear_grading_criteria_loss: 0.0931 - course_difficulty_course_difficulty_mae: 0.6507 - course_difficulty_loss: 0.6798 - extra_credit_extra_credit_recall: 0.0000e+00 - extra_credit_loss: 0.0557 - get_ready_to_read_get_ready_to_read_recall: 9.9704e-04 - get_ready_to_read_loss: 0.1330 - gives_good_feedback_gives_good_feedback_recall: 0.0000e+00 - gives_good_feedback_loss: 0.1024 - graded_by_few_things_graded_by_few_things_recall: 0.0000e+00 - graded_by_few_things_loss: 0.1250 - group_projects_group_projects_recall: 0.0000e+00 - group_projects_loss: 0.0782 - hilarious_hilarious_recall: 0.0000e+00 - hilarious_loss: 0.1001 - inspirational_inspirational_recall: 0.0145 - inspirational_loss: 0.0743 - lecture_heavy_lecture_heavy_recall: 0.0000e+00 - lecture_heavy_loss: 0.1195 - loss: 3.1145 - lots_of_homework_loss: 0.1003 - lots_of_homework_lots_of_homework_recall: 0.0000e+00 - participation_matters_loss: 0.1165 - participation_matters_participation_matters_recall: 0.0000e+00 - respected_loss: 0.0988 - respected_respected_recall: 0.0090 - skip_class_you_wont_pass_loss: 0.1171 - skip_class_you_wont_pass_skip_class_you_wont_pass_recall: 0.0000e+00 - so_many_papers_loss: 0.0572 - so_many_papers_so_many_papers_recall: 0.0000e+00 - star_rating_loss: 0.4678 - star_rating_star_rating_mae: 0.5379 - test_heavy_loss: 0.1079 - test_heavy_test_heavy_recall: 5.7440e-04 - tests_are_tough_loss: 0.0216 - tests_are_tough_tests_are_tough_recall: 0.0000e+00 - tough_grader_loss: 0.1036 - tough_grader_tough_grader_recall: 0.6251 - would_take_again_loss: 0.0188 - would_take_again_would_take_again_recall: 0.0000e+00 - val_accessible_outside_class_accessible_outside_class_recall: 0.0000e+00 - val_accessible_outside_class_loss: 0.0958 - val_amazing_lectures_amazing_lectures_recall: 0.0000e+00 - val_amazing_lectures_loss: 0.1003 - val_beware_of_pop_quizzes_beware_of_pop_quizzes_recall: 0.0000e+00 - val_beware_of_pop_quizzes_loss: 0.0325 - val_caring_caring_recall: 0.0000e+00 - val_caring_loss: 0.1070 - val_clear_grading_criteria_clear_grading_criteria_recall: 0.0000e+00 - val_clear_grading_criteria_loss: 0.0895 - val_course_difficulty_course_difficulty_mae: 0.8028 - val_course_difficulty_loss: 1.0249 - val_extra_credit_extra_credit_recall: 0.0000e+00 - val_extra_credit_loss: 0.0488 - val_get_ready_to_read_get_ready_to_read_recall: 0.0000e+00 - val_get_ready_to_read_loss: 0.1329 - val_gives_good_feedback_gives_good_feedback_recall: 0.0000e+00 - val_gives_good_feedback_loss: 0.1064 - val_graded_by_few_things_graded_by_few_things_recall: 0.0000e+00 - val_graded_by_few_things_loss: 0.1012 - val_group_projects_group_projects_recall: 0.0000e+00 - val_group_projects_loss: 0.0542 - val_hilarious_hilarious_recall: 0.0000e+00 - val_hilarious_loss: 0.0937 - val_inspirational_inspirational_recall: 0.0000e+00 - val_inspirational_loss: 0.0794 - val_lecture_heavy_lecture_heavy_recall: 0.0000e+00 - val_lecture_heavy_loss: 0.1201 - val_loss: 3.6382 - val_lots_of_homework_loss: 0.0986 - val_lots_of_homework_lots_of_homework_recall: 0.0000e+00 - val_participation_matters_loss: 0.1033 - val_participation_matters_participation_matters_recall: 0.0000e+00 - val_respected_loss: 0.1014 - val_respected_respected_recall: 0.0000e+00 - val_skip_class_you_wont_pass_loss: 0.1088 - val_skip_class_you_wont_pass_skip_class_you_wont_pass_recall: 0.0000e+00 - val_so_many_papers_loss: 0.0450 - val_so_many_papers_so_many_papers_recall: 0.0000e+00 - val_star_rating_loss: 0.7482 - val_star_rating_star_rating_mae: 0.5926 - val_test_heavy_loss: 0.0954 - val_test_heavy_test_heavy_recall: 0.0000e+00 - val_tests_are_tough_loss: 0.0113 - val_tests_are_tough_tests_are_tough_recall: 0.0000e+00 - val_tough_grader_loss: 0.1248 - val_tough_grader_tough_grader_recall: 0.5533 - val_would_take_again_loss: 0.0125 - val_would_take_again_would_take_again_recall: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    X_train,\n",
    "    [y_train[col] for col in y_train.columns],\n",
    "    epochs=1,\n",
    "    batch_size=32,\n",
    "    validation_split=0.2,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fyLlntGU00r5",
    "outputId": "19d831b1-cb28-42d7-eea2-ce1b8050fcc9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance for Different Thresholds:\n",
      "                  Output  Threshold  Mean Absolute Error   Recall  Precision  F1-Score  Accuracy\n",
      "             star_rating       0.20             0.607398      NaN        NaN       NaN       NaN\n",
      "       course_difficulty       0.20             0.805254      NaN        NaN       NaN       NaN\n",
      "     gives_good_feedback       0.20                  NaN 0.957105   0.220280  0.358134  0.452354\n",
      "                  caring       0.20                  NaN 0.969489   0.255940  0.404971  0.467190\n",
      "               respected       0.20                  NaN 0.940577   0.232236  0.372500  0.467475\n",
      "   participation_matters       0.20                  NaN 1.000000   0.139658  0.245087  0.139658\n",
      "  clear_grading_criteria       0.20                  NaN 0.935523   0.151318  0.260501  0.377175\n",
      "        amazing_lectures       0.20                  NaN 0.947819   0.256126  0.403276  0.532240\n",
      "           inspirational       0.20                  NaN 0.921212   0.152572  0.261787  0.510842\n",
      "            tough_grader       0.20                  NaN 0.950559   0.327786  0.487474  0.515549\n",
      "               hilarious       0.20                  NaN 0.955241   0.151052  0.260856  0.344365\n",
      "       get_ready_to_read       0.20                  NaN 1.000000   0.218260  0.358314  0.218260\n",
      "        lots_of_homework       0.20                  NaN 0.934004   0.147266  0.254418  0.301854\n",
      "accessible_outside_class       0.20                  NaN 0.949412   0.153393  0.264114  0.358488\n",
      "           lecture_heavy       0.20                  NaN 0.989300   0.179136  0.303344  0.212411\n",
      "            extra_credit       0.20                  NaN 0.844444   0.046798  0.088681  0.331526\n",
      "    graded_by_few_things       0.20                  NaN 1.000000   0.134495  0.237100  0.135235\n",
      "          group_projects       0.20                  NaN 0.969101   0.051895  0.098515  0.099287\n",
      "        would_take_again       0.20                  NaN 0.017857   0.052632  0.026667  0.989586\n",
      "skip_class_you_wont_pass       0.20                  NaN 0.998946   0.135622  0.238821  0.137946\n",
      "              test_heavy       0.20                  NaN 0.939933   0.161229  0.275244  0.365193\n",
      "          so_many_papers       0.20                  NaN 0.775000   0.055473  0.103535  0.540514\n",
      "   beware_of_pop_quizzes       0.20                  NaN 0.685714   0.035566  0.067625  0.527960\n",
      "         tests_are_tough       0.20                  NaN 0.022727   0.003390  0.005900  0.951926\n",
      "             star_rating       0.21             0.607398      NaN        NaN       NaN       NaN\n",
      "       course_difficulty       0.21             0.805254      NaN        NaN       NaN       NaN\n",
      "     gives_good_feedback       0.21                  NaN 0.953530   0.221507  0.359501  0.457632\n",
      "                  caring       0.21                  NaN 0.967201   0.258196  0.407586  0.474180\n",
      "               respected       0.21                  NaN 0.938879   0.234770  0.375616  0.475464\n",
      "   participation_matters       0.21                  NaN 1.000000   0.139658  0.245087  0.139658\n",
      "  clear_grading_criteria       0.21                  NaN 0.934307   0.152988  0.262924  0.385735\n",
      "        amazing_lectures       0.21                  NaN 0.943541   0.258617  0.405962  0.539515\n",
      "           inspirational       0.21                  NaN 0.912121   0.154359  0.264035  0.521255\n",
      "            tough_grader       0.21                  NaN 0.942319   0.333750  0.492919  0.530100\n",
      "               hilarious       0.21                  NaN 0.951708   0.153495  0.264355  0.358488\n",
      "       get_ready_to_read       0.21                  NaN 1.000000   0.218260  0.358314  0.218260\n",
      "        lots_of_homework       0.21                  NaN 0.916107   0.150193  0.258075  0.328245\n",
      "accessible_outside_class       0.21                  NaN 0.948235   0.155119  0.266623  0.367475\n",
      "           lecture_heavy       0.21                  NaN 0.981893   0.182751  0.308149  0.235806\n",
      "            extra_credit       0.21                  NaN 0.814815   0.048469  0.091495  0.376748\n",
      "    graded_by_few_things       0.21                  NaN 1.000000   0.135364  0.238451  0.141655\n",
      "          group_projects       0.21                  NaN 0.938202   0.054327  0.102706  0.167475\n",
      "        would_take_again       0.21                  NaN 0.017857   0.250000  0.033333  0.991726\n",
      "skip_class_you_wont_pass       0.21                  NaN 0.995785   0.136541  0.240152  0.146933\n",
      "              test_heavy       0.21                  NaN 0.928810   0.165642  0.281145  0.390870\n",
      "          so_many_papers       0.21                  NaN 0.750000   0.056497  0.105079  0.562625\n",
      "   beware_of_pop_quizzes       0.21                  NaN 0.657143   0.036323  0.068842  0.556205\n",
      "         tests_are_tough       0.21                  NaN 0.022727   0.006369  0.009950  0.971612\n",
      "             star_rating       0.22             0.607398      NaN        NaN       NaN       NaN\n",
      "       course_difficulty       0.22             0.805254      NaN        NaN       NaN       NaN\n",
      "     gives_good_feedback       0.22                  NaN 0.950849   0.223201  0.361536  0.463909\n",
      "                  caring       0.22                  NaN 0.961098   0.259794  0.409025  0.480599\n",
      "               respected       0.22                  NaN 0.934635   0.235962  0.376797  0.480456\n",
      "   participation_matters       0.22                  NaN 1.000000   0.139658  0.245087  0.139658\n",
      "  clear_grading_criteria       0.22                  NaN 0.924574   0.153257  0.262930  0.392154\n",
      "        amazing_lectures       0.22                  NaN 0.941831   0.261272  0.409066  0.546220\n",
      "           inspirational       0.22                  NaN 0.904545   0.156734  0.267174  0.532810\n",
      "            tough_grader       0.22                  NaN 0.937022   0.341778  0.500865  0.547361\n",
      "               hilarious       0.22                  NaN 0.945819   0.155500  0.267088  0.371327\n",
      "       get_ready_to_read       0.22                  NaN 1.000000   0.218322  0.358398  0.218545\n",
      "        lots_of_homework       0.22                  NaN 0.902685   0.154037  0.263166  0.355350\n",
      "accessible_outside_class       0.22                  NaN 0.943529   0.156702  0.268767  0.377461\n",
      "           lecture_heavy       0.22                  NaN 0.975309   0.186438  0.313037  0.258060\n",
      "            extra_credit       0.22                  NaN 0.770370   0.050036  0.093969  0.427817\n",
      "    graded_by_few_things       0.22                  NaN 0.992569   0.136896  0.240607  0.158060\n",
      "          group_projects       0.22                  NaN 0.870787   0.056652  0.106383  0.257061\n",
      "        would_take_again       0.22                  NaN 0.000000   0.000000  0.000000  0.992011\n",
      "skip_class_you_wont_pass       0.22                  NaN 0.992624   0.138062  0.242409  0.160057\n",
      "              test_heavy       0.22                  NaN 0.919911   0.170375  0.287502  0.415264\n",
      "          so_many_papers       0.22                  NaN 0.733333   0.057971  0.107448  0.582882\n",
      "   beware_of_pop_quizzes       0.22                  NaN 0.640000   0.037597  0.071021  0.582026\n",
      "         tests_are_tough       0.22                  NaN 0.000000   0.000000  0.000000  0.983880\n",
      "             star_rating       0.23             0.607398      NaN        NaN       NaN       NaN\n",
      "       course_difficulty       0.23             0.805254      NaN        NaN       NaN       NaN\n",
      "     gives_good_feedback       0.23                  NaN 0.948168   0.225074  0.363792  0.470613\n",
      "                  caring       0.23                  NaN 0.955759   0.261696  0.410887  0.487447\n",
      "               respected       0.23                  NaN 0.932088   0.237920  0.379078  0.486876\n",
      "   participation_matters       0.23                  NaN 1.000000   0.139658  0.245087  0.139658\n",
      "  clear_grading_criteria       0.23                  NaN 0.919708   0.154855  0.265077  0.401997\n",
      "        amazing_lectures       0.23                  NaN 0.939264   0.264515  0.412782  0.554351\n",
      "           inspirational       0.23                  NaN 0.895455   0.158956  0.269986  0.544080\n",
      "            tough_grader       0.23                  NaN 0.929959   0.348632  0.507142  0.561912\n",
      "               hilarious       0.23                  NaN 0.943463   0.157584  0.270061  0.382311\n",
      "       get_ready_to_read       0.23                  NaN 0.999346   0.218678  0.358836  0.220542\n",
      "        lots_of_homework       0.23                  NaN 0.889262   0.156836  0.266644  0.376177\n",
      "accessible_outside_class       0.23                  NaN 0.942353   0.158645  0.271571  0.387019\n",
      "           lecture_heavy       0.23                  NaN 0.962140   0.190143  0.317534  0.283167\n",
      "            extra_credit       0.23                  NaN 0.729630   0.052338  0.097670  0.480742\n",
      "    graded_by_few_things       0.23                  NaN 0.984076   0.139587  0.244494  0.182739\n",
      "          group_projects       0.23                  NaN 0.766854   0.058684  0.109026  0.363481\n",
      "        would_take_again       0.23                  NaN 0.000000   0.000000  0.000000  0.992011\n",
      "skip_class_you_wont_pass       0.23                  NaN 0.986301   0.139576  0.244546  0.175036\n",
      "              test_heavy       0.23                  NaN 0.909900   0.174973  0.293506  0.438231\n",
      "          so_many_papers       0.23                  NaN 0.716667   0.059147  0.109276  0.600000\n",
      "   beware_of_pop_quizzes       0.23                  NaN 0.617143   0.038737  0.072899  0.608131\n",
      "         tests_are_tough       0.23                  NaN 0.000000   0.000000  0.000000  0.991155\n",
      "             star_rating       0.24             0.607398      NaN        NaN       NaN       NaN\n",
      "       course_difficulty       0.24             0.805254      NaN        NaN       NaN       NaN\n",
      "     gives_good_feedback       0.24                  NaN 0.946381   0.226864  0.365993  0.476605\n",
      "                  caring       0.24                  NaN 0.951182   0.264027  0.413324  0.495007\n",
      "               respected       0.24                  NaN 0.929542   0.240501  0.382132  0.494864\n",
      "   participation_matters       0.24                  NaN 1.000000   0.139658  0.245087  0.139658\n",
      "  clear_grading_criteria       0.24                  NaN 0.911192   0.156204  0.266690  0.412411\n",
      "        amazing_lectures       0.24                  NaN 0.934132   0.266406  0.414579  0.560057\n",
      "           inspirational       0.24                  NaN 0.893939   0.162804  0.275444  0.557204\n",
      "            tough_grader       0.24                  NaN 0.922896   0.355394  0.513173  0.575606\n",
      "               hilarious       0.24                  NaN 0.935218   0.159023  0.271825  0.393153\n",
      "       get_ready_to_read       0.24                  NaN 0.998039   0.220124  0.360694  0.227817\n",
      "        lots_of_homework       0.24                  NaN 0.880313   0.160842  0.271989  0.399001\n",
      "accessible_outside_class       0.24                  NaN 0.938824   0.160338  0.273897  0.396434\n",
      "           lecture_heavy       0.24                  NaN 0.955556   0.195323  0.324347  0.309986\n",
      "            extra_credit       0.24                  NaN 0.681481   0.054942  0.101686  0.536234\n",
      "    graded_by_few_things       0.24                  NaN 0.975584   0.144315  0.251436  0.219401\n",
      "          group_projects       0.24                  NaN 0.632022   0.058777  0.107553  0.467332\n",
      "        would_take_again       0.24                  NaN 0.000000   0.000000  0.000000  0.992011\n",
      "skip_class_you_wont_pass       0.24                  NaN 0.972603   0.140787  0.245969  0.192725\n",
      "              test_heavy       0.24                  NaN 0.895439   0.178849  0.298148  0.459344\n",
      "          so_many_papers       0.24                  NaN 0.700000   0.060193  0.110855  0.615549\n",
      "   beware_of_pop_quizzes       0.24                  NaN 0.565714   0.040016  0.074745  0.650357\n",
      "         tests_are_tough       0.24                  NaN 0.000000   0.000000  0.000000  0.993723\n",
      "             star_rating       0.25             0.607398      NaN        NaN       NaN       NaN\n",
      "       course_difficulty       0.25             0.805254      NaN        NaN       NaN       NaN\n",
      "     gives_good_feedback       0.25                  NaN 0.941019   0.228317  0.367475  0.482882\n",
      "                  caring       0.25                  NaN 0.945080   0.265481  0.414520  0.500713\n",
      "               respected       0.25                  NaN 0.926146   0.242822  0.384765  0.502282\n",
      "   participation_matters       0.25                  NaN 1.000000   0.139658  0.245087  0.139658\n",
      "  clear_grading_criteria       0.25                  NaN 0.906326   0.157605  0.268517  0.420970\n",
      "        amazing_lectures       0.25                  NaN 0.931565   0.270425  0.419169  0.569472\n",
      "           inspirational       0.25                  NaN 0.877273   0.165193  0.278031  0.571041\n",
      "            tough_grader       0.25                  NaN 0.918776   0.365061  0.522510  0.593010\n",
      "               hilarious       0.25                  NaN 0.926973   0.160809  0.274073  0.405278\n",
      "       get_ready_to_read       0.25                  NaN 0.994771   0.222287  0.363376  0.239230\n",
      "        lots_of_homework       0.25                  NaN 0.865772   0.164786  0.276874  0.423252\n",
      "accessible_outside_class       0.25                  NaN 0.935294   0.161585  0.275563  0.403709\n",
      "           lecture_heavy       0.25                  NaN 0.941564   0.198922  0.328452  0.332668\n",
      "            extra_credit       0.25                  NaN 0.611111   0.056526  0.103481  0.592154\n",
      "    graded_by_few_things       0.25                  NaN 0.955414   0.148368  0.256849  0.257061\n",
      "          group_projects       0.25                  NaN 0.539326   0.063703  0.113947  0.574037\n",
      "        would_take_again       0.25                  NaN 0.000000   0.000000  0.000000  0.992011\n",
      "skip_class_you_wont_pass       0.25                  NaN 0.961012   0.143216  0.249282  0.216405\n",
      "              test_heavy       0.25                  NaN 0.879867   0.183357  0.303472  0.482026\n",
      "          so_many_papers       0.25                  NaN 0.683333   0.061957  0.113613  0.634950\n",
      "   beware_of_pop_quizzes       0.25                  NaN 0.428571   0.039144  0.071736  0.723110\n",
      "         tests_are_tough       0.25                  NaN 0.000000   0.000000  0.000000  0.993723\n",
      "             star_rating       0.26             0.607398      NaN        NaN       NaN       NaN\n",
      "       course_difficulty       0.26             0.805254      NaN        NaN       NaN       NaN\n",
      "     gives_good_feedback       0.26                  NaN 0.934763   0.229941  0.369090  0.489872\n",
      "                  caring       0.26                  NaN 0.940503   0.266825  0.415711  0.505563\n",
      "               respected       0.26                  NaN 0.920204   0.245917  0.388113  0.512411\n",
      "   participation_matters       0.26                  NaN 1.000000   0.139658  0.245087  0.139658\n",
      "  clear_grading_criteria       0.26                  NaN 0.899027   0.159370  0.270746  0.432097\n",
      "        amazing_lectures       0.26                  NaN 0.927288   0.273185  0.422036  0.576462\n",
      "           inspirational       0.26                  NaN 0.868182   0.169176  0.283173  0.586163\n",
      "            tough_grader       0.26                  NaN 0.912890   0.371853  0.528450  0.605136\n",
      "               hilarious       0.26                  NaN 0.922261   0.163739  0.278103  0.420114\n",
      "       get_ready_to_read       0.26                  NaN 0.990196   0.225514  0.367362  0.255635\n",
      "        lots_of_homework       0.26                  NaN 0.851230   0.168214  0.280915  0.444223\n",
      "accessible_outside_class       0.26                  NaN 0.929412   0.162920  0.277242  0.412411\n",
      "           lecture_heavy       0.26                  NaN 0.931687   0.203159  0.333579  0.354779\n",
      "            extra_credit       0.26                  NaN 0.570370   0.061087  0.110355  0.645792\n",
      "    graded_by_few_things       0.26                  NaN 0.936306   0.153471  0.263717  0.297432\n",
      "          group_projects       0.26                  NaN 0.435393   0.066839  0.115888  0.662625\n",
      "        would_take_again       0.26                  NaN 0.000000   0.000000  0.000000  0.992011\n",
      "skip_class_you_wont_pass       0.26                  NaN 0.944152   0.145525  0.252181  0.241940\n",
      "              test_heavy       0.26                  NaN 0.866518   0.188894  0.310173  0.505706\n",
      "          so_many_papers       0.26                  NaN 0.600000   0.059455  0.108189  0.661341\n",
      "   beware_of_pop_quizzes       0.26                  NaN 0.262857   0.035034  0.061828  0.800856\n",
      "         tests_are_tough       0.26                  NaN 0.000000   0.000000  0.000000  0.993723\n",
      "             star_rating       0.27             0.607398      NaN        NaN       NaN       NaN\n",
      "       course_difficulty       0.27             0.805254      NaN        NaN       NaN       NaN\n",
      "     gives_good_feedback       0.27                  NaN 0.931189   0.232071  0.371546  0.497147\n",
      "                  caring       0.27                  NaN 0.932876   0.269561  0.418263  0.514693\n",
      "               respected       0.27                  NaN 0.909168   0.247745  0.389384  0.520827\n",
      "   participation_matters       0.27                  NaN 1.000000   0.139658  0.245087  0.139658\n",
      "  clear_grading_criteria       0.27                  NaN 0.892944   0.161212  0.273116  0.442653\n",
      "        amazing_lectures       0.27                  NaN 0.923011   0.276171  0.425138  0.583738\n",
      "           inspirational       0.27                  NaN 0.862121   0.174915  0.290825  0.604137\n",
      "            tough_grader       0.27                  NaN 0.903473   0.378358  0.533356  0.616833\n",
      "               hilarious       0.27                  NaN 0.911661   0.166023  0.280893  0.434665\n",
      "       get_ready_to_read       0.27                  NaN 0.979085   0.229122  0.371344  0.276462\n",
      "        lots_of_homework       0.27                  NaN 0.832215   0.171113  0.283861  0.464479\n",
      "accessible_outside_class       0.27                  NaN 0.917647   0.163180  0.277087  0.419401\n",
      "           lecture_heavy       0.27                  NaN 0.916049   0.207031  0.337733  0.377318\n",
      "            extra_credit       0.27                  NaN 0.522222   0.066761  0.118388  0.700428\n",
      "    graded_by_few_things       0.27                  NaN 0.918259   0.158803  0.270778  0.335378\n",
      "          group_projects       0.27                  NaN 0.359551   0.074462  0.123373  0.740514\n",
      "        would_take_again       0.27                  NaN 0.000000   0.000000  0.000000  0.992011\n",
      "skip_class_you_wont_pass       0.27                  NaN 0.920969   0.148261  0.255406  0.273039\n",
      "              test_heavy       0.27                  NaN 0.857620   0.194845  0.317545  0.527247\n",
      "          so_many_papers       0.27                  NaN 0.450000   0.061259  0.107838  0.745078\n",
      "   beware_of_pop_quizzes       0.27                  NaN 0.148571   0.034076  0.055437  0.873609\n",
      "         tests_are_tough       0.27                  NaN 0.000000   0.000000  0.000000  0.993723\n",
      "             star_rating       0.28             0.607398      NaN        NaN       NaN       NaN\n",
      "       course_difficulty       0.28             0.805254      NaN        NaN       NaN       NaN\n",
      "     gives_good_feedback       0.28                  NaN 0.924039   0.234202  0.373690  0.505563\n",
      "                  caring       0.28                  NaN 0.929062   0.273033  0.422037  0.524108\n",
      "               respected       0.28                  NaN 0.903226   0.250589  0.392330  0.529815\n",
      "   participation_matters       0.28                  NaN 1.000000   0.139717  0.245179  0.140086\n",
      "  clear_grading_criteria       0.28                  NaN 0.883212   0.162562  0.274584  0.452782\n",
      "        amazing_lectures       0.28                  NaN 0.917023   0.279094  0.427944  0.591155\n",
      "           inspirational       0.28                  NaN 0.848485   0.180296  0.297398  0.622539\n",
      "            tough_grader       0.28                  NaN 0.894644   0.387064  0.540348  0.631098\n",
      "               hilarious       0.28                  NaN 0.898704   0.167877  0.282907  0.448217\n",
      "       get_ready_to_read       0.28                  NaN 0.969281   0.234022  0.377018  0.300856\n",
      "        lots_of_homework       0.28                  NaN 0.807606   0.174438  0.286906  0.488017\n",
      "accessible_outside_class       0.28                  NaN 0.916471   0.165288  0.280065  0.428673\n",
      "           lecture_heavy       0.28                  NaN 0.905350   0.211416  0.342786  0.398288\n",
      "            extra_credit       0.28                  NaN 0.440741   0.069146  0.119538  0.749929\n",
      "    graded_by_few_things       0.28                  NaN 0.895966   0.164362  0.277769  0.373894\n",
      "          group_projects       0.28                  NaN 0.297753   0.082555  0.129268  0.796291\n",
      "        would_take_again       0.28                  NaN 0.000000   0.000000  0.000000  0.992011\n",
      "skip_class_you_wont_pass       0.28                  NaN 0.896733   0.150994  0.258466  0.303424\n",
      "              test_heavy       0.28                  NaN 0.840934   0.199052  0.321908  0.545649\n",
      "          so_many_papers       0.28                  NaN 0.245833   0.056568  0.091972  0.833809\n",
      "   beware_of_pop_quizzes       0.28                  NaN 0.062857   0.032544  0.042885  0.929957\n",
      "         tests_are_tough       0.28                  NaN 0.000000   0.000000  0.000000  0.993723\n",
      "             star_rating       0.29             0.607398      NaN        NaN       NaN       NaN\n",
      "       course_difficulty       0.29             0.805254      NaN        NaN       NaN       NaN\n",
      "     gives_good_feedback       0.29                  NaN 0.921358   0.238106  0.378418  0.516833\n",
      "                  caring       0.29                  NaN 0.921434   0.275862  0.424605  0.532953\n",
      "               respected       0.29                  NaN 0.891341   0.252222  0.393185  0.537660\n",
      "   participation_matters       0.29                  NaN 0.973442   0.142324  0.248339  0.177033\n",
      "  clear_grading_criteria       0.29                  NaN 0.873479   0.164264  0.276526  0.464051\n",
      "        amazing_lectures       0.29                  NaN 0.911035   0.282418  0.431174  0.599144\n",
      "           inspirational       0.29                  NaN 0.833333   0.185811  0.303867  0.640514\n",
      "            tough_grader       0.29                  NaN 0.885815   0.392950  0.544402  0.640656\n",
      "               hilarious       0.29                  NaN 0.884570   0.171657  0.287519  0.469044\n",
      "       get_ready_to_read       0.29                  NaN 0.958170   0.237987  0.381274  0.321255\n",
      "        lots_of_homework       0.29                  NaN 0.781879   0.178135  0.290162  0.512126\n",
      "accessible_outside_class       0.29                  NaN 0.911765   0.167459  0.282950  0.439658\n",
      "           lecture_heavy       0.29                  NaN 0.891358   0.215180  0.346671  0.417689\n",
      "            extra_credit       0.29                  NaN 0.370370   0.072464  0.121212  0.793153\n",
      "    graded_by_few_things       0.29                  NaN 0.868365   0.169358  0.283437  0.409986\n",
      "          group_projects       0.29                  NaN 0.230337   0.086498  0.125767  0.837375\n",
      "        would_take_again       0.29                  NaN 0.000000   0.000000  0.000000  0.992011\n",
      "skip_class_you_wont_pass       0.29                  NaN 0.870390   0.153875  0.261517  0.334522\n",
      "              test_heavy       0.29                  NaN 0.816463   0.203099  0.325283  0.565621\n",
      "          so_many_papers       0.29                  NaN 0.125000   0.061224  0.082192  0.904422\n",
      "   beware_of_pop_quizzes       0.29                  NaN 0.005714   0.014706  0.008230  0.965621\n",
      "         tests_are_tough       0.29                  NaN 0.000000   0.000000  0.000000  0.993723\n",
      "             star_rating       0.30             0.607398      NaN        NaN       NaN       NaN\n",
      "       course_difficulty       0.30             0.805254      NaN        NaN       NaN       NaN\n",
      "     gives_good_feedback       0.30                  NaN 0.911528   0.240170  0.380171  0.525535\n",
      "                  caring       0.30                  NaN 0.913806   0.278864  0.427323  0.541940\n",
      "               respected       0.30                  NaN 0.881154   0.254661  0.395128  0.546648\n",
      "   participation_matters       0.30                  NaN 0.909091   0.147742  0.254177  0.254922\n",
      "  clear_grading_criteria       0.30                  NaN 0.861314   0.166314  0.278795  0.477461\n",
      "        amazing_lectures       0.30                  NaN 0.896493   0.285248  0.432790  0.608131\n",
      "           inspirational       0.30                  NaN 0.809091   0.190919  0.308938  0.659201\n",
      "            tough_grader       0.30                  NaN 0.874044   0.398337  0.547264  0.649501\n",
      "               hilarious       0.30                  NaN 0.866902   0.175238  0.291543  0.489729\n",
      "       get_ready_to_read       0.30                  NaN 0.942484   0.243006  0.386388  0.346648\n",
      "        lots_of_homework       0.30                  NaN 0.758389   0.181429  0.292809  0.532810\n",
      "accessible_outside_class       0.30                  NaN 0.900000   0.168688  0.284123  0.450071\n",
      "           lecture_heavy       0.30                  NaN 0.877366   0.219206  0.350773  0.437090\n",
      "            extra_credit       0.30                  NaN 0.303704   0.075996  0.121572  0.830956\n",
      "    graded_by_few_things       0.30                  NaN 0.838641   0.176734  0.291944  0.453352\n",
      "          group_projects       0.30                  NaN 0.165730   0.086257  0.113462  0.868474\n",
      "        would_take_again       0.30                  NaN 0.000000   0.000000  0.000000  0.992011\n",
      "skip_class_you_wont_pass       0.30                  NaN 0.838778   0.156724  0.264101  0.367190\n",
      "              test_heavy       0.30                  NaN 0.793103   0.207267  0.328647  0.584451\n",
      "          so_many_papers       0.30                  NaN 0.029167   0.060870  0.039437  0.951355\n",
      "   beware_of_pop_quizzes       0.30                  NaN 0.000000   0.000000  0.000000  0.975036\n",
      "         tests_are_tough       0.30                  NaN 0.000000   0.000000  0.000000  0.993723\n",
      "\n",
      "Average F1-Score for Different Thresholds:\n",
      "Threshold 0.20: Average F1-Score = 0.2444\n",
      "Threshold 0.21: Average F1-Score = 0.2473\n",
      "Threshold 0.22: Average F1-Score = 0.2478\n",
      "Threshold 0.23: Average F1-Score = 0.2504\n",
      "Threshold 0.24: Average F1-Score = 0.2532\n",
      "Threshold 0.25: Average F1-Score = 0.2559\n",
      "Threshold 0.26: Average F1-Score = 0.2583\n",
      "Threshold 0.27: Average F1-Score = 0.2612\n",
      "Threshold 0.28: Average F1-Score = 0.2630\n",
      "Threshold 0.29: Average F1-Score = 0.2635\n",
      "Threshold 0.30: Average F1-Score = 0.2632\n",
      "\n",
      "Average Regression MAE: 0.7063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_absolute_error, recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Create a list to store the results\n",
    "results = []\n",
    "thresholds = np.arange(0.29, 0.30, 0.01)  # Thresholds from 0.2 to 0.3 with 0.01 increments\n",
    "\n",
    "# Iterate over each threshold and calculate the F1-score for classification tasks\n",
    "for threshold in thresholds:\n",
    "    threshold_results = []\n",
    "    for i, col in enumerate(y_test.columns):\n",
    "        if y_test[col].dtype == 'float64':\n",
    "            # For regression tasks, calculate Mean Absolute Error\n",
    "            mae = mean_absolute_error(y_test[col], y_pred[i])\n",
    "            threshold_results.append({\n",
    "                'Output': col,\n",
    "                'Threshold': threshold,\n",
    "                'Mean Absolute Error': mae,\n",
    "                'Recall': None,\n",
    "                'Precision': None,\n",
    "                'F1-Score': None,\n",
    "                'Accuracy': None\n",
    "            })\n",
    "        else:\n",
    "            # For binary classification tasks, calculate Recall, Precision, F1-Score, and Accuracy\n",
    "            y_pred_binary = (y_pred[i] > threshold).astype(int)\n",
    "            recall = recall_score(y_test[col], y_pred_binary)\n",
    "            precision = precision_score(y_test[col], y_pred_binary)\n",
    "            f1 = f1_score(y_test[col], y_pred_binary)\n",
    "            accuracy = accuracy_score(y_test[col], y_pred_binary)\n",
    "\n",
    "            threshold_results.append({\n",
    "                'Output': col,\n",
    "                'Threshold': threshold,\n",
    "                'Mean Absolute Error': None,\n",
    "                'Recall': recall,\n",
    "                'Precision': precision,\n",
    "                'F1-Score': f1,\n",
    "                'Accuracy': accuracy\n",
    "            })\n",
    "    results.extend(threshold_results)\n",
    "\n",
    "# Create the DataFrame from the results list\n",
    "performance_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results\n",
    "print(\"Model Performance for Different Thresholds:\")\n",
    "print(performance_df.to_string(index=False))\n",
    "\n",
    "# Calculate and display average F1-Score for each threshold\n",
    "print(\"\\nAverage F1-Score for Different Thresholds:\")\n",
    "for threshold in thresholds:\n",
    "    avg_f1 = performance_df[(performance_df['Threshold'] == threshold) & (performance_df['F1-Score'].notna())]['F1-Score'].mean()\n",
    "    print(f\"Threshold {threshold:.2f}: Average F1-Score = {avg_f1:.4f}\")\n",
    "\n",
    "# Calculate and display average MAE for regression tasks\n",
    "regression_mae = performance_df['Mean Absolute Error'].mean()\n",
    "print(f\"\\nAverage Regression MAE: {regression_mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m220/220\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 27ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance for Different Thresholds:\n",
      "                  Output  Threshold  Mean Absolute Error   Recall  Precision  F1-Score  Accuracy\n",
      "             star_rating        0.1             0.607398      NaN        NaN       NaN       NaN\n",
      "       course_difficulty        0.1             0.805254      NaN        NaN       NaN       NaN\n",
      "     gives_good_feedback        0.1                  NaN 0.980340   0.202175  0.335218  0.379315\n",
      "                  caring        0.1                  NaN 0.985507   0.231417  0.374819  0.385164\n",
      "               respected        0.1                  NaN 0.964346   0.213735  0.349915  0.397860\n",
      "   participation_matters        0.1                  NaN 1.000000   0.139658  0.245087  0.139658\n",
      "  clear_grading_criteria        0.1                  NaN 0.980535   0.135576  0.238215  0.264622\n",
      "        amazing_lectures        0.1                  NaN 0.972626   0.234047  0.377302  0.464622\n",
      "           inspirational        0.1                  NaN 0.957576   0.134240  0.235469  0.414551\n",
      "            tough_grader        0.1                  NaN 0.991760   0.261402  0.413751  0.318830\n",
      "               hilarious        0.1                  NaN 0.997644   0.122771  0.218637  0.136377\n",
      "       get_ready_to_read        0.1                  NaN 1.000000   0.218260  0.358314  0.218260\n",
      "        lots_of_homework        0.1                  NaN 1.000000   0.127532  0.226215  0.127532\n",
      "accessible_outside_class        0.1                  NaN 0.991765   0.130334  0.230391  0.196576\n",
      "           lecture_heavy        0.1                  NaN 1.000000   0.173324  0.295441  0.173324\n",
      "            extra_credit        0.1                  NaN 0.962963   0.040254  0.077277  0.114265\n",
      "    graded_by_few_things        0.1                  NaN 1.000000   0.134379  0.236922  0.134379\n",
      "          group_projects        0.1                  NaN 1.000000   0.050785  0.096660  0.050785\n",
      "        would_take_again        0.1                  NaN 0.892857   0.012749  0.025138  0.446790\n",
      "skip_class_you_wont_pass        0.1                  NaN 1.000000   0.135378  0.238472  0.135378\n",
      "              test_heavy        0.1                  NaN 1.000000   0.128319  0.227451  0.128816\n",
      "          so_many_papers        0.1                  NaN 0.975000   0.039308  0.075569  0.183310\n",
      "   beware_of_pop_quizzes        0.1                  NaN 1.000000   0.025652  0.050021  0.051783\n",
      "         tests_are_tough        0.1                  NaN 0.613636   0.010063  0.019802  0.618688\n",
      "             star_rating        0.2             0.607398      NaN        NaN       NaN       NaN\n",
      "       course_difficulty        0.2             0.805254      NaN        NaN       NaN       NaN\n",
      "     gives_good_feedback        0.2                  NaN 0.957105   0.220280  0.358134  0.452354\n",
      "                  caring        0.2                  NaN 0.969489   0.255940  0.404971  0.467190\n",
      "               respected        0.2                  NaN 0.940577   0.232236  0.372500  0.467475\n",
      "   participation_matters        0.2                  NaN 1.000000   0.139658  0.245087  0.139658\n",
      "  clear_grading_criteria        0.2                  NaN 0.935523   0.151318  0.260501  0.377175\n",
      "        amazing_lectures        0.2                  NaN 0.947819   0.256126  0.403276  0.532240\n",
      "           inspirational        0.2                  NaN 0.921212   0.152572  0.261787  0.510842\n",
      "            tough_grader        0.2                  NaN 0.950559   0.327786  0.487474  0.515549\n",
      "               hilarious        0.2                  NaN 0.955241   0.151052  0.260856  0.344365\n",
      "       get_ready_to_read        0.2                  NaN 1.000000   0.218260  0.358314  0.218260\n",
      "        lots_of_homework        0.2                  NaN 0.934004   0.147266  0.254418  0.301854\n",
      "accessible_outside_class        0.2                  NaN 0.949412   0.153393  0.264114  0.358488\n",
      "           lecture_heavy        0.2                  NaN 0.989300   0.179136  0.303344  0.212411\n",
      "            extra_credit        0.2                  NaN 0.844444   0.046798  0.088681  0.331526\n",
      "    graded_by_few_things        0.2                  NaN 1.000000   0.134495  0.237100  0.135235\n",
      "          group_projects        0.2                  NaN 0.969101   0.051895  0.098515  0.099287\n",
      "        would_take_again        0.2                  NaN 0.017857   0.052632  0.026667  0.989586\n",
      "skip_class_you_wont_pass        0.2                  NaN 0.998946   0.135622  0.238821  0.137946\n",
      "              test_heavy        0.2                  NaN 0.939933   0.161229  0.275244  0.365193\n",
      "          so_many_papers        0.2                  NaN 0.775000   0.055473  0.103535  0.540514\n",
      "   beware_of_pop_quizzes        0.2                  NaN 0.685714   0.035566  0.067625  0.527960\n",
      "         tests_are_tough        0.2                  NaN 0.022727   0.003390  0.005900  0.951926\n",
      "             star_rating        0.3             0.607398      NaN        NaN       NaN       NaN\n",
      "       course_difficulty        0.3             0.805254      NaN        NaN       NaN       NaN\n",
      "     gives_good_feedback        0.3                  NaN 0.911528   0.240170  0.380171  0.525535\n",
      "                  caring        0.3                  NaN 0.913806   0.278864  0.427323  0.541940\n",
      "               respected        0.3                  NaN 0.881154   0.254661  0.395128  0.546648\n",
      "   participation_matters        0.3                  NaN 0.909091   0.147742  0.254177  0.254922\n",
      "  clear_grading_criteria        0.3                  NaN 0.861314   0.166314  0.278795  0.477461\n",
      "        amazing_lectures        0.3                  NaN 0.896493   0.285248  0.432790  0.608131\n",
      "           inspirational        0.3                  NaN 0.809091   0.190919  0.308938  0.659201\n",
      "            tough_grader        0.3                  NaN 0.874044   0.398337  0.547264  0.649501\n",
      "               hilarious        0.3                  NaN 0.866902   0.175238  0.291543  0.489729\n",
      "       get_ready_to_read        0.3                  NaN 0.942484   0.243006  0.386388  0.346648\n",
      "        lots_of_homework        0.3                  NaN 0.758389   0.181429  0.292809  0.532810\n",
      "accessible_outside_class        0.3                  NaN 0.900000   0.168688  0.284123  0.450071\n",
      "           lecture_heavy        0.3                  NaN 0.877366   0.219206  0.350773  0.437090\n",
      "            extra_credit        0.3                  NaN 0.303704   0.075996  0.121572  0.830956\n",
      "    graded_by_few_things        0.3                  NaN 0.838641   0.176734  0.291944  0.453352\n",
      "          group_projects        0.3                  NaN 0.165730   0.086257  0.113462  0.868474\n",
      "        would_take_again        0.3                  NaN 0.000000   0.000000  0.000000  0.992011\n",
      "skip_class_you_wont_pass        0.3                  NaN 0.838778   0.156724  0.264101  0.367190\n",
      "              test_heavy        0.3                  NaN 0.793103   0.207267  0.328647  0.584451\n",
      "          so_many_papers        0.3                  NaN 0.029167   0.060870  0.039437  0.951355\n",
      "   beware_of_pop_quizzes        0.3                  NaN 0.000000   0.000000  0.000000  0.975036\n",
      "         tests_are_tough        0.3                  NaN 0.000000   0.000000  0.000000  0.993723\n",
      "             star_rating        0.4             0.607398      NaN        NaN       NaN       NaN\n",
      "       course_difficulty        0.4             0.805254      NaN        NaN       NaN       NaN\n",
      "     gives_good_feedback        0.4                  NaN 0.566577   0.286618  0.380666  0.705706\n",
      "                  caring        0.4                  NaN 0.693364   0.329946  0.447122  0.679315\n",
      "               respected        0.4                  NaN 0.562818   0.317225  0.405753  0.722967\n",
      "   participation_matters        0.4                  NaN 0.000000   0.000000  0.000000  0.860342\n",
      "  clear_grading_criteria        0.4                  NaN 0.144769   0.253731  0.184353  0.849786\n",
      "        amazing_lectures        0.4                  NaN 0.650128   0.353160  0.457693  0.743081\n",
      "           inspirational        0.4                  NaN 0.277273   0.294686  0.285714  0.869472\n",
      "            tough_grader        0.4                  NaN 0.779871   0.468695  0.585506  0.732382\n",
      "               hilarious        0.4                  NaN 0.048292   0.344538  0.084711  0.873609\n",
      "       get_ready_to_read        0.4                  NaN 0.630719   0.289355  0.396711  0.581312\n",
      "        lots_of_homework        0.4                  NaN 0.002237   0.250000  0.004435  0.871897\n",
      "accessible_outside_class        0.4                  NaN 0.007059   0.214286  0.013667  0.876462\n",
      "           lecture_heavy        0.4                  NaN 0.178601   0.291275  0.221429  0.782311\n",
      "            extra_credit        0.4                  NaN 0.000000   0.000000  0.000000  0.961484\n",
      "    graded_by_few_things        0.4                  NaN 0.074310   0.247350  0.114286  0.845221\n",
      "          group_projects        0.4                  NaN 0.000000   0.000000  0.000000  0.949215\n",
      "        would_take_again        0.4                  NaN 0.000000   0.000000  0.000000  0.992011\n",
      "skip_class_you_wont_pass        0.4                  NaN 0.011591   0.323529  0.022380  0.862910\n",
      "              test_heavy        0.4                  NaN 0.331479   0.272146  0.298897  0.800571\n",
      "          so_many_papers        0.4                  NaN 0.000000   0.000000  0.000000  0.965763\n",
      "   beware_of_pop_quizzes        0.4                  NaN 0.000000   0.000000  0.000000  0.975036\n",
      "         tests_are_tough        0.4                  NaN 0.000000   0.000000  0.000000  0.993723\n",
      "             star_rating        0.5             0.607398      NaN        NaN       NaN       NaN\n",
      "       course_difficulty        0.5             0.805254      NaN        NaN       NaN       NaN\n",
      "     gives_good_feedback        0.5                  NaN 0.000000   0.000000  0.000000  0.840371\n",
      "                  caring        0.5                  NaN 0.000000   0.000000  0.000000  0.812981\n",
      "               respected        0.5                  NaN 0.000000   0.000000  0.000000  0.831954\n",
      "   participation_matters        0.5                  NaN 0.000000   0.000000  0.000000  0.860342\n",
      "  clear_grading_criteria        0.5                  NaN 0.000000   0.000000  0.000000  0.882739\n",
      "        amazing_lectures        0.5                  NaN 0.000000   0.000000  0.000000  0.833238\n",
      "           inspirational        0.5                  NaN 0.000000   0.000000  0.000000  0.905849\n",
      "            tough_grader        0.5                  NaN 0.544438   0.547986  0.546206  0.780742\n",
      "               hilarious        0.5                  NaN 0.000000   0.000000  0.000000  0.878887\n",
      "       get_ready_to_read        0.5                  NaN 0.000000   0.000000  0.000000  0.781740\n",
      "        lots_of_homework        0.5                  NaN 0.000000   0.000000  0.000000  0.872468\n",
      "accessible_outside_class        0.5                  NaN 0.000000   0.000000  0.000000  0.878745\n",
      "           lecture_heavy        0.5                  NaN 0.000000   0.000000  0.000000  0.826676\n",
      "            extra_credit        0.5                  NaN 0.000000   0.000000  0.000000  0.961484\n",
      "    graded_by_few_things        0.5                  NaN 0.000000   0.000000  0.000000  0.865621\n",
      "          group_projects        0.5                  NaN 0.000000   0.000000  0.000000  0.949215\n",
      "        would_take_again        0.5                  NaN 0.000000   0.000000  0.000000  0.992011\n",
      "skip_class_you_wont_pass        0.5                  NaN 0.000000   0.000000  0.000000  0.864622\n",
      "              test_heavy        0.5                  NaN 0.000000   0.000000  0.000000  0.871755\n",
      "          so_many_papers        0.5                  NaN 0.000000   0.000000  0.000000  0.965763\n",
      "   beware_of_pop_quizzes        0.5                  NaN 0.000000   0.000000  0.000000  0.975036\n",
      "         tests_are_tough        0.5                  NaN 0.000000   0.000000  0.000000  0.993723\n",
      "             star_rating        0.6             0.607398      NaN        NaN       NaN       NaN\n",
      "       course_difficulty        0.6             0.805254      NaN        NaN       NaN       NaN\n",
      "     gives_good_feedback        0.6                  NaN 0.000000   0.000000  0.000000  0.840371\n",
      "                  caring        0.6                  NaN 0.000000   0.000000  0.000000  0.812981\n",
      "               respected        0.6                  NaN 0.000000   0.000000  0.000000  0.831954\n",
      "   participation_matters        0.6                  NaN 0.000000   0.000000  0.000000  0.860342\n",
      "  clear_grading_criteria        0.6                  NaN 0.000000   0.000000  0.000000  0.882739\n",
      "        amazing_lectures        0.6                  NaN 0.000000   0.000000  0.000000  0.833238\n",
      "           inspirational        0.6                  NaN 0.000000   0.000000  0.000000  0.905849\n",
      "            tough_grader        0.6                  NaN 0.005886   0.909091  0.011696  0.758916\n",
      "               hilarious        0.6                  NaN 0.000000   0.000000  0.000000  0.878887\n",
      "       get_ready_to_read        0.6                  NaN 0.000000   0.000000  0.000000  0.781740\n",
      "        lots_of_homework        0.6                  NaN 0.000000   0.000000  0.000000  0.872468\n",
      "accessible_outside_class        0.6                  NaN 0.000000   0.000000  0.000000  0.878745\n",
      "           lecture_heavy        0.6                  NaN 0.000000   0.000000  0.000000  0.826676\n",
      "            extra_credit        0.6                  NaN 0.000000   0.000000  0.000000  0.961484\n",
      "    graded_by_few_things        0.6                  NaN 0.000000   0.000000  0.000000  0.865621\n",
      "          group_projects        0.6                  NaN 0.000000   0.000000  0.000000  0.949215\n",
      "        would_take_again        0.6                  NaN 0.000000   0.000000  0.000000  0.992011\n",
      "skip_class_you_wont_pass        0.6                  NaN 0.000000   0.000000  0.000000  0.864622\n",
      "              test_heavy        0.6                  NaN 0.000000   0.000000  0.000000  0.871755\n",
      "          so_many_papers        0.6                  NaN 0.000000   0.000000  0.000000  0.965763\n",
      "   beware_of_pop_quizzes        0.6                  NaN 0.000000   0.000000  0.000000  0.975036\n",
      "         tests_are_tough        0.6                  NaN 0.000000   0.000000  0.000000  0.993723\n",
      "             star_rating        0.7             0.607398      NaN        NaN       NaN       NaN\n",
      "       course_difficulty        0.7             0.805254      NaN        NaN       NaN       NaN\n",
      "     gives_good_feedback        0.7                  NaN 0.000000   0.000000  0.000000  0.840371\n",
      "                  caring        0.7                  NaN 0.000000   0.000000  0.000000  0.812981\n",
      "               respected        0.7                  NaN 0.000000   0.000000  0.000000  0.831954\n",
      "   participation_matters        0.7                  NaN 0.000000   0.000000  0.000000  0.860342\n",
      "  clear_grading_criteria        0.7                  NaN 0.000000   0.000000  0.000000  0.882739\n",
      "        amazing_lectures        0.7                  NaN 0.000000   0.000000  0.000000  0.833238\n",
      "           inspirational        0.7                  NaN 0.000000   0.000000  0.000000  0.905849\n",
      "            tough_grader        0.7                  NaN 0.000000   0.000000  0.000000  0.757632\n",
      "               hilarious        0.7                  NaN 0.000000   0.000000  0.000000  0.878887\n",
      "       get_ready_to_read        0.7                  NaN 0.000000   0.000000  0.000000  0.781740\n",
      "        lots_of_homework        0.7                  NaN 0.000000   0.000000  0.000000  0.872468\n",
      "accessible_outside_class        0.7                  NaN 0.000000   0.000000  0.000000  0.878745\n",
      "           lecture_heavy        0.7                  NaN 0.000000   0.000000  0.000000  0.826676\n",
      "            extra_credit        0.7                  NaN 0.000000   0.000000  0.000000  0.961484\n",
      "    graded_by_few_things        0.7                  NaN 0.000000   0.000000  0.000000  0.865621\n",
      "          group_projects        0.7                  NaN 0.000000   0.000000  0.000000  0.949215\n",
      "        would_take_again        0.7                  NaN 0.000000   0.000000  0.000000  0.992011\n",
      "skip_class_you_wont_pass        0.7                  NaN 0.000000   0.000000  0.000000  0.864622\n",
      "              test_heavy        0.7                  NaN 0.000000   0.000000  0.000000  0.871755\n",
      "          so_many_papers        0.7                  NaN 0.000000   0.000000  0.000000  0.965763\n",
      "   beware_of_pop_quizzes        0.7                  NaN 0.000000   0.000000  0.000000  0.975036\n",
      "         tests_are_tough        0.7                  NaN 0.000000   0.000000  0.000000  0.993723\n",
      "             star_rating        0.8             0.607398      NaN        NaN       NaN       NaN\n",
      "       course_difficulty        0.8             0.805254      NaN        NaN       NaN       NaN\n",
      "     gives_good_feedback        0.8                  NaN 0.000000   0.000000  0.000000  0.840371\n",
      "                  caring        0.8                  NaN 0.000000   0.000000  0.000000  0.812981\n",
      "               respected        0.8                  NaN 0.000000   0.000000  0.000000  0.831954\n",
      "   participation_matters        0.8                  NaN 0.000000   0.000000  0.000000  0.860342\n",
      "  clear_grading_criteria        0.8                  NaN 0.000000   0.000000  0.000000  0.882739\n",
      "        amazing_lectures        0.8                  NaN 0.000000   0.000000  0.000000  0.833238\n",
      "           inspirational        0.8                  NaN 0.000000   0.000000  0.000000  0.905849\n",
      "            tough_grader        0.8                  NaN 0.000000   0.000000  0.000000  0.757632\n",
      "               hilarious        0.8                  NaN 0.000000   0.000000  0.000000  0.878887\n",
      "       get_ready_to_read        0.8                  NaN 0.000000   0.000000  0.000000  0.781740\n",
      "        lots_of_homework        0.8                  NaN 0.000000   0.000000  0.000000  0.872468\n",
      "accessible_outside_class        0.8                  NaN 0.000000   0.000000  0.000000  0.878745\n",
      "           lecture_heavy        0.8                  NaN 0.000000   0.000000  0.000000  0.826676\n",
      "            extra_credit        0.8                  NaN 0.000000   0.000000  0.000000  0.961484\n",
      "    graded_by_few_things        0.8                  NaN 0.000000   0.000000  0.000000  0.865621\n",
      "          group_projects        0.8                  NaN 0.000000   0.000000  0.000000  0.949215\n",
      "        would_take_again        0.8                  NaN 0.000000   0.000000  0.000000  0.992011\n",
      "skip_class_you_wont_pass        0.8                  NaN 0.000000   0.000000  0.000000  0.864622\n",
      "              test_heavy        0.8                  NaN 0.000000   0.000000  0.000000  0.871755\n",
      "          so_many_papers        0.8                  NaN 0.000000   0.000000  0.000000  0.965763\n",
      "   beware_of_pop_quizzes        0.8                  NaN 0.000000   0.000000  0.000000  0.975036\n",
      "         tests_are_tough        0.8                  NaN 0.000000   0.000000  0.000000  0.993723\n",
      "Threshold 0.10: Average F1-Score = 0.2248\n",
      "Threshold 0.20: Average F1-Score = 0.2444\n",
      "Threshold 0.30: Average F1-Score = 0.2632\n",
      "Threshold 0.40: Average F1-Score = 0.1774\n",
      "Threshold 0.50: Average F1-Score = 0.0248\n",
      "Threshold 0.60: Average F1-Score = 0.0005\n",
      "Threshold 0.70: Average F1-Score = 0.0000\n",
      "Threshold 0.80: Average F1-Score = 0.0000\n",
      "\n",
      "Average Regression MAE: 0.7063\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error, recall_score, precision_score, f1_score, accuracy_score\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Create a list to store the results\n",
    "results = []\n",
    "thresholds = np.arange(0.1, 0.9, 0.1)  # Thresholds from 0.2 to 0.3 with 0.01 increments\n",
    "\n",
    "# Iterate over each threshold and calculate the F1-score for classification tasks\n",
    "for threshold in thresholds:\n",
    "    threshold_results = []\n",
    "    for i, col in enumerate(y_test.columns):\n",
    "        if y_test[col].dtype == 'float64':\n",
    "            # For regression tasks, calculate Mean Absolute Error\n",
    "            mae = mean_absolute_error(y_test[col], y_pred[i])\n",
    "            threshold_results.append({\n",
    "                'Output': col,\n",
    "                'Threshold': threshold,\n",
    "                'Mean Absolute Error': mae,\n",
    "                'Recall': None,\n",
    "                'Precision': None,\n",
    "                'F1-Score': None,\n",
    "                'Accuracy': None\n",
    "            })\n",
    "        else:\n",
    "            # For binary classification tasks, calculate Recall, Precision, F1-Score, and Accuracy\n",
    "            y_pred_binary = (y_pred[i] > threshold).astype(int)\n",
    "            recall = recall_score(y_test[col], y_pred_binary)\n",
    "            precision = precision_score(y_test[col], y_pred_binary)\n",
    "            f1 = f1_score(y_test[col], y_pred_binary)\n",
    "            accuracy = accuracy_score(y_test[col], y_pred_binary)\n",
    "\n",
    "            threshold_results.append({\n",
    "                'Output': col,\n",
    "                'Threshold': threshold,\n",
    "                'Mean Absolute Error': None,\n",
    "                'Recall': recall,\n",
    "                'Precision': precision,\n",
    "                'F1-Score': f1,\n",
    "                'Accuracy': accuracy\n",
    "            })\n",
    "    results.extend(threshold_results)\n",
    "\n",
    "# Create the DataFrame from the results list\n",
    "performance_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results\n",
    "print(\"Model Performance for Different Thresholds:\")\n",
    "print(performance_df.to_string(index=False))\n",
    "\n",
    "# Calculate and display average F1-Score for each threshold\n",
    "avg_f1_scores = []\n",
    "avg_recalls = []\n",
    "avg_precisions = []\n",
    "avg_accuracies = []\n",
    "for threshold in thresholds:\n",
    "    avg_f1 = performance_df[(performance_df['Threshold'] == threshold) & (performance_df['F1-Score'].notna())]['F1-Score'].mean()\n",
    "    avg_recall = performance_df[(performance_df['Threshold'] == threshold) & (performance_df['Recall'].notna())]['Recall'].mean()\n",
    "    avg_precision = performance_df[(performance_df['Threshold'] == threshold) & (performance_df['Precision'].notna())]['Precision'].mean()\n",
    "    avg_accuracy = performance_df[(performance_df['Threshold'] == threshold) & (performance_df['Accuracy'].notna())]['Accuracy'].mean()\n",
    "    avg_f1_scores.append(avg_f1)\n",
    "    avg_recalls.append(avg_recall)\n",
    "    avg_precisions.append(avg_precision)\n",
    "    avg_accuracies.append(avg_accuracy)\n",
    "    print(f\"Threshold {threshold:.2f}: Average F1-Score = {avg_f1:.4f}\")\n",
    "\n",
    "# Calculate and display average MAE for regression tasks\n",
    "regression_mae = performance_df['Mean Absolute Error'].mean()\n",
    "print(f\"\\nAverage Regression MAE: {regression_mae:.4f}\")\n",
    "\n",
    "# Plot Precision, Recall, and F1-Score against thresholds\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(thresholds, avg_precisions, label='Average Precision', marker='o')\n",
    "plt.plot(thresholds, avg_recalls, label='Average Recall', marker='o')\n",
    "plt.plot(thresholds, avg_f1_scores, label='Average F1-Score', marker='o')\n",
    "plt.plot(thresholds, avg_accuracies, label='Average Accuracy', marker='o')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Precision, Recall, and F1-Score vs. Threshold')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.9.2-cp312-cp312-macosx_10_12_x86_64.whl.metadata (11 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.3.1-cp312-cp312-macosx_10_13_x86_64.whl.metadata (5.4 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.55.0-cp312-cp312-macosx_10_13_x86_64.whl.metadata (164 kB)\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.7-cp312-cp312-macosx_10_9_x86_64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: numpy>=1.23 in /Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages (from matplotlib) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages (from matplotlib) (24.1)\n",
      "Collecting pillow>=8 (from matplotlib)\n",
      "  Downloading pillow-11.0.0-cp312-cp312-macosx_10_13_x86_64.whl.metadata (9.1 kB)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages (from matplotlib) (3.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages (from matplotlib) (2.9.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/yuanshenwang/miniconda3/envs/544/lib/python3.12/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.9.2-cp312-cp312-macosx_10_12_x86_64.whl (7.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading contourpy-1.3.1-cp312-cp312-macosx_10_13_x86_64.whl (271 kB)\n",
      "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.55.0-cp312-cp312-macosx_10_13_x86_64.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading kiwisolver-1.4.7-cp312-cp312-macosx_10_9_x86_64.whl (65 kB)\n",
      "Downloading pillow-11.0.0-cp312-cp312-macosx_10_13_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pillow, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.3.1 cycler-0.12.1 fonttools-4.55.0 kiwisolver-1.4.7 matplotlib-3.9.2 pillow-11.0.0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "544",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
