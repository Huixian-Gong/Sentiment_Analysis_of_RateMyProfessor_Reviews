{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOmb7ims96V/Q7jJTFDSUm6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["# Load the Drive helper and mount\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DHwfW5ptjGQM","executionInfo":{"status":"ok","timestamp":1730159633434,"user_tz":420,"elapsed":24227,"user":{"displayName":"Ying Sun","userId":"07331030295783244436"}},"outputId":"6695e7fa-241c-42d1-bbfd-8d4dda83d355"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from transformers import AutoModelForSequenceClassification, AutoTokenizer\n","import torch\n","from torch.nn.functional import sigmoid\n","\n","def load_model():\n","    # Load model and tokenizer\n","    model_path = '/content/drive/MyDrive/Colab Notebooks/544/project/saved'\n","    model = AutoModelForSequenceClassification.from_pretrained(model_path)\n","    tokenizer = AutoTokenizer.from_pretrained('roberta-base')\n","\n","    # Move to GPU if available\n","    device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","    model = model.to(device)\n","    model.eval()\n","\n","    return model, tokenizer, device\n","\n","def predict_professor(comment, model, tokenizer, device):\n","    \"\"\"\n","    Predict ratings and tags for a professor's comment\n","    Returns:\n","        - difficulty rating (0-5)\n","        - student rating (0-5)\n","        - gives_good_feedback (boolean)\n","        - caring (boolean)\n","        - respected (boolean)\n","    \"\"\"\n","    # Tokenize input\n","    inputs = tokenizer(comment, return_tensors=\"pt\", truncation=True, padding=True, max_length=512)\n","    inputs = {k: v.to(device) for k, v in inputs.items()}\n","\n","    # Get predictions\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","        logits = outputs.logits\n","\n","        # First two outputs are ratings (0-5)\n","        difficulty = logits[0, 0].item()\n","        student_rating = logits[0, 1].item()\n","\n","        # Last three outputs are binary tags\n","        tags = sigmoid(logits[0, 2:]).cpu().numpy()\n","\n","    return {\n","        'difficulty_rating': round(difficulty, 2),\n","        'student_rating': round(student_rating, 2),\n","        'gives_good_feedback': bool(tags[0] > 0.5),\n","        'caring': bool(tags[1] > 0.5),\n","        'respected': bool(tags[2] > 0.5),\n","        'tag_probabilities': {\n","            'gives_good_feedback': round(float(tags[0]) * 100, 2),\n","            'caring': round(float(tags[1]) * 100, 2),\n","            'respected': round(float(tags[2]) * 100, 2)\n","        }\n","    }\n","\n","# Load model\n","model, tokenizer, device = load_model()\n","\n","# Interactive prediction loop\n","while True:\n","    # Get user input\n","    comment = input(\"\\nEnter professor comment (or 'quit' to exit): \")\n","\n","    if comment.lower() == 'quit':\n","        break\n","\n","    # Get predictions\n","    results = predict_professor(comment, model, tokenizer, device)\n","\n","    # Print results\n","    print(\"\\nPredictions:\")\n","    print(f\"Difficulty Rating: {results['difficulty_rating']}/5\")\n","    print(f\"Student Rating: {results['student_rating']}/5\")\n","    print(\"\\nTags:\")\n","    print(f\"Gives Good Feedback: {results['gives_good_feedback']} ({results['tag_probabilities']['gives_good_feedback']}%)\")\n","    print(f\"Caring: {results['caring']} ({results['tag_probabilities']['caring']}%)\")\n","    print(f\"Respected: {results['respected']} ({results['tag_probabilities']['respected']}%)\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YXWRP7YmjzxB","executionInfo":{"status":"ok","timestamp":1730160283886,"user_tz":420,"elapsed":42091,"user":{"displayName":"Ying Sun","userId":"07331030295783244436"}},"outputId":"83d3258c-db70-4b44-ab29-cab28e9acc6b"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["\n","Enter professor comment (or 'quit' to exit): this is good\n","\n","Predictions:\n","Difficulty Rating: 2.26/5\n","Student Rating: 4.41/5\n","\n","Tags:\n","Gives Good Feedback: False (30.85%)\n","Caring: False (26.96%)\n","Respected: False (29.02%)\n","\n","Enter professor comment (or 'quit' to exit): \"Trouble is, if you have different opin- ions on the topics you talk about then she won´t like you. As long as you stick to what she lays out you should be good. She wants very badly to have students she molds, if she can´t mold you she´ll throw you away.\n","\n","Predictions:\n","Difficulty Rating: 3.8/5\n","Student Rating: 2.83/5\n","\n","Tags:\n","Gives Good Feedback: False (25.24%)\n","Caring: False (21.31%)\n","Respected: False (20.96%)\n","\n","Enter professor comment (or 'quit' to exit): quit\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"hsFYd9DFlium"},"execution_count":null,"outputs":[]}]}